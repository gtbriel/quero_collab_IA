{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from db_connection import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = db_connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSERTING VALUES ON TABLES\n",
    "\n",
    "sql = \"\"\"INSERT INTO quero_collab.authors (author_id, profile_id, name) VALUES (%s, %s, %s)\"\"\"\n",
    "db_insert(conn, sql, [(9, 9, 'Lucas Amorim')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"INSERT INTO quero_collab.authors (post_id, author_id, text_data) VALUES (%d, %d, %s, %s)\"\"\"\n",
    "db_insert(conn, sql, [(3, 3, 'Lucas Amorim', '')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('profiles', 'profile_id', 'integer'),\n",
       " ('profiles', 'interests', 'ARRAY'),\n",
       " ('profiles', 'team_id', 'integer')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = db_consume(conn, \"\"\"SELECT \n",
    "                                    table_name, \n",
    "                                    column_name, \n",
    "                                    data_type \n",
    "                                FROM \n",
    "                                    information_schema.columns\n",
    "                                where\n",
    "                                    table_name = 'profiles'\"\"\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  1,\n",
       "  'Atualmente estou desenvolvendo um script que consome a API do Google Search Console, para auxiliar o time de SEO',\n",
       "  datetime.datetime(2022, 4, 10, 0, 7, 55, 115183)),\n",
       " (2,\n",
       "  2,\n",
       "  'Antes de criar algo, verifique se já não foi criado!! Experiência própria com Rails',\n",
       "  datetime.datetime(2022, 4, 10, 0, 9, 10, 524515)),\n",
       " (3,\n",
       "  7,\n",
       "  'Atualmente estou trabalhando em uma nova funcionalidade do ETL para processar tabelas de campus. O ETL é uma api que o siteOps usa.',\n",
       "  datetime.datetime(2022, 4, 10, 5, 7, 10, 494339)),\n",
       " (4,\n",
       "  8,\n",
       "  'Estou trabalhando em uma nova funcionalidade do EXP para extrair ids de campus conforme um filtro dado',\n",
       "  datetime.datetime(2022, 4, 10, 5, 7, 30, 304825)),\n",
       " (5,\n",
       "  9,\n",
       "  'Estou montando uma tabela padrão de campus com regras bem definidas.',\n",
       "  datetime.datetime(2022, 4, 10, 5, 7, 45, 620612)),\n",
       " (6,\n",
       "  4,\n",
       "  'Começamos a desenvolver um script que consome dados da API do Google Ads e gera algumas visualizações pro time de Growth, task bem desafiadora porque nunca utilizamos API do Google...',\n",
       "  datetime.datetime(2022, 4, 10, 5, 10, 0, 342631)),\n",
       " (7,\n",
       "  1,\n",
       "  'Prestar manutenção ao PPA é muito trabalhoso',\n",
       "  datetime.datetime(2022, 3, 26, 5, 14, 48, 433638)),\n",
       " (8,\n",
       "  1,\n",
       "  'Vamos conseguir finalmente matar o PPA!!',\n",
       "  datetime.datetime(2022, 4, 7, 5, 15, 23, 912749))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = db_consume(conn, \"\"\"SELECT * FROM posts\"\"\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/hevelyncarvalho/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/hevelyncarvalho/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/hevelyncarvalho/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/hevelyncarvalho/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from similarity import *\n",
    "from db_connection import *\n",
    "conn = db_connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation \"quero_collab.posts\" does not exist\n",
      "LINE 1: SELECT * FROM quero_collab.posts where date(created_at) >= '...\n",
      "                      ^\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_id = 1\n",
    "delta_time = (datetime.datetime.today() - datetime.timedelta(7)).strftime('%Y-%m-%d')    \n",
    "response = db_consume(conn, f\"SELECT * FROM quero_collab.posts where date(created_at) >= '{delta_time}' and author_id != {user_id}\")\n",
    "\n",
    "postsDF = pandas.DataFrame(response, columns=['post_id', 'author_id', 'text_data', 'created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "you must first build vocabulary before training the model",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/hevelyncarvalho/Documents/quero_collab_IA/functions/example_insert.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/hevelyncarvalho/Documents/quero_collab_IA/functions/example_insert.ipynb#ch0000011?line=0'>1</a>\u001b[0m model_post \u001b[39m=\u001b[39m get_model(postsDF[\u001b[39m'\u001b[39;49m\u001b[39mtext_data\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[0;32m~/Documents/quero_collab_IA/functions/similarity.py:33\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(posts)\u001b[0m\n\u001b[1;32m     <a href='file:///home/hevelyncarvalho/Documents/quero_collab_IA/functions/similarity.py?line=30'>31</a>\u001b[0m tagged_posts \u001b[39m=\u001b[39m [TaggedDocument(doc, [i]) \u001b[39mfor\u001b[39;00m i, doc \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(keywords)] \n\u001b[1;32m     <a href='file:///home/hevelyncarvalho/Documents/quero_collab_IA/functions/similarity.py?line=31'>32</a>\u001b[0m d2v\u001b[39m.\u001b[39mbuild_vocab(documents\u001b[39m=\u001b[39mtagged_posts)\n\u001b[0;32m---> <a href='file:///home/hevelyncarvalho/Documents/quero_collab_IA/functions/similarity.py?line=32'>33</a>\u001b[0m total \u001b[39m=\u001b[39m d2v\u001b[39m.\u001b[39mcorpus_count\n\u001b[1;32m     <a href='file:///home/hevelyncarvalho/Documents/quero_collab_IA/functions/similarity.py?line=33'>34</a>\u001b[0m d2v\u001b[39m.\u001b[39mtrain(tagged_posts, total_examples\u001b[39m=\u001b[39mtotal, epochs\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)    \n\u001b[1;32m     <a href='file:///home/hevelyncarvalho/Documents/quero_collab_IA/functions/similarity.py?line=34'>35</a>\u001b[0m \u001b[39mreturn\u001b[39;00m d2v\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/gensim/models/doc2vec.py:792\u001b[0m, in \u001b[0;36mDoc2Vec.train\u001b[0;34m(self, documents, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, callbacks)\u001b[0m\n\u001b[1;32m    <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/gensim/models/doc2vec.py?line=788'>789</a>\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39moffsets\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m offsets\n\u001b[1;32m    <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/gensim/models/doc2vec.py?line=789'>790</a>\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstart_doctags\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m start_doctags\n\u001b[0;32m--> <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/gensim/models/doc2vec.py?line=791'>792</a>\u001b[0m \u001b[39msuper\u001b[39;49m(Doc2Vec, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m    <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/gensim/models/doc2vec.py?line=792'>793</a>\u001b[0m     sentences\u001b[39m=\u001b[39;49mdocuments, corpus_file\u001b[39m=\u001b[39;49mcorpus_file, total_examples\u001b[39m=\u001b[39;49mtotal_examples, total_words\u001b[39m=\u001b[39;49mtotal_words,\n\u001b[1;32m    <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/gensim/models/doc2vec.py?line=793'>794</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs, start_alpha\u001b[39m=\u001b[39;49mstart_alpha, end_alpha\u001b[39m=\u001b[39;49mend_alpha, word_count\u001b[39m=\u001b[39;49mword_count,\n\u001b[1;32m    <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/gensim/models/doc2vec.py?line=794'>795</a>\u001b[0m     queue_factor\u001b[39m=\u001b[39;49mqueue_factor, report_delay\u001b[39m=\u001b[39;49mreport_delay, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/gensim/models/base_any2vec.py:1077\u001b[0m, in \u001b[0;36mBaseWordEmbeddingsModel.train\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/gensim/models/base_any2vec.py?line=1074'>1075</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss \u001b[39m=\u001b[39m compute_loss\n\u001b[1;32m   <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/gensim/models/base_any2vec.py?line=1075'>1076</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_training_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m-> <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/gensim/models/base_any2vec.py?line=1076'>1077</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(BaseWordEmbeddingsModel, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m   <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/gensim/models/base_any2vec.py?line=1077'>1078</a>\u001b[0m     data_iterable\u001b[39m=\u001b[39;49msentences, corpus_file\u001b[39m=\u001b[39;49mcorpus_file, total_examples\u001b[39m=\u001b[39;49mtotal_examples,\n\u001b[1;32m   <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/gensim/models/base_any2vec.py?line=1078'>1079</a>\u001b[0m     total_words\u001b[39m=\u001b[39;49mtotal_words, epochs\u001b[39m=\u001b[39;49mepochs, start_alpha\u001b[39m=\u001b[39;49mstart_alpha, end_alpha\u001b[39m=\u001b[39;49mend_alpha, word_count\u001b[39m=\u001b[39;49mword_count,\n\u001b[1;32m   <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/gensim/models/base_any2vec.py?line=1079'>1080</a>\u001b[0m     queue_factor\u001b[39m=\u001b[39;49mqueue_factor, report_delay\u001b[39m=\u001b[39;49mreport_delay, compute_loss\u001b[39m=\u001b[39;49mcompute_loss, callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/gensim/models/base_any2vec.py?line=1080'>1081</a>\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/gensim/models/base_any2vec.py:533\u001b[0m, in \u001b[0;36mBaseAny2VecModel.train\u001b[0;34m(self, data_iterable, corpus_file, epochs, total_examples, total_words, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/gensim/models/base_any2vec.py?line=530'>531</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks \u001b[39m=\u001b[39m callbacks\n\u001b[1;32m    <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/gensim/models/base_any2vec.py?line=531'>532</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepochs \u001b[39m=\u001b[39m epochs\n\u001b[0;32m--> <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/gensim/models/base_any2vec.py?line=532'>533</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_training_sanity(\n\u001b[1;32m    <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/gensim/models/base_any2vec.py?line=533'>534</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m    <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/gensim/models/base_any2vec.py?line=534'>535</a>\u001b[0m     total_examples\u001b[39m=\u001b[39;49mtotal_examples,\n\u001b[1;32m    <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/gensim/models/base_any2vec.py?line=535'>536</a>\u001b[0m     total_words\u001b[39m=\u001b[39;49mtotal_words, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/gensim/models/base_any2vec.py?line=537'>538</a>\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[1;32m    <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/gensim/models/base_any2vec.py?line=538'>539</a>\u001b[0m     callback\u001b[39m.\u001b[39mon_train_begin(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/gensim/models/base_any2vec.py:1187\u001b[0m, in \u001b[0;36mBaseWordEmbeddingsModel._check_training_sanity\u001b[0;34m(self, epochs, total_examples, total_words, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/gensim/models/base_any2vec.py?line=1183'>1184</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mParameters for training were discarded using model_trimmed_post_training method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/gensim/models/base_any2vec.py?line=1185'>1186</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwv\u001b[39m.\u001b[39mvocab:  \u001b[39m# should be set by `build_vocab`\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/gensim/models/base_any2vec.py?line=1186'>1187</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39myou must first build vocabulary before training the model\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/gensim/models/base_any2vec.py?line=1187'>1188</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwv\u001b[39m.\u001b[39mvectors):\n\u001b[1;32m   <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/gensim/models/base_any2vec.py?line=1188'>1189</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39myou must initialize vectors before training the model\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: you must first build vocabulary before training the model"
     ]
    }
   ],
   "source": [
    "model_post = get_model(postsDF['text_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#tokens = get_tokens_from_posts(user_id, postsDF)  \n",
    "\n",
    "print(\"get model\")\n",
    "model_post = get_model(postsDF['text_data'])\n",
    "print(\"get sims\")\n",
    "metricsDF = get_posts_sims(model_post, postsDF)\n",
    "print(metricsDF)\n",
    "\n",
    "   \n",
    "\n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = metricsDF['date'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No axis named 6 for object type Series",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py:550\u001b[0m, in \u001b[0;36mNDFrame._get_axis_number\u001b[0;34m(cls, axis)\u001b[0m\n\u001b[1;32m    <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/pandas/core/generic.py?line=548'>549</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/pandas/core/generic.py?line=549'>550</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_AXIS_TO_AXIS_NUMBER[axis]\n\u001b[1;32m    <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/pandas/core/generic.py?line=550'>551</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 6",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/hevelyncarvalho/Documents/quero_collab_IA/functions/example_insert.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hevelyncarvalho/Documents/quero_collab_IA/functions/example_insert.ipynb#ch0000008?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m a:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/hevelyncarvalho/Documents/quero_collab_IA/functions/example_insert.ipynb#ch0000008?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(df\u001b[39m.\u001b[39;49miloc(i))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py:634\u001b[0m, in \u001b[0;36m_LocationIndexer.__call__\u001b[0;34m(self, axis)\u001b[0m\n\u001b[1;32m    <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/pandas/core/indexing.py?line=630'>631</a>\u001b[0m new_self \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[1;32m    <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/pandas/core/indexing.py?line=632'>633</a>\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/pandas/core/indexing.py?line=633'>634</a>\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49m_get_axis_number(axis)\n\u001b[1;32m    <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/pandas/core/indexing.py?line=634'>635</a>\u001b[0m new_self\u001b[39m.\u001b[39maxis \u001b[39m=\u001b[39m axis\n\u001b[1;32m    <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/pandas/core/indexing.py?line=635'>636</a>\u001b[0m \u001b[39mreturn\u001b[39;00m new_self\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py:552\u001b[0m, in \u001b[0;36mNDFrame._get_axis_number\u001b[0;34m(cls, axis)\u001b[0m\n\u001b[1;32m    <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/pandas/core/generic.py?line=549'>550</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_AXIS_TO_AXIS_NUMBER[axis]\n\u001b[1;32m    <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/pandas/core/generic.py?line=550'>551</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/hevelyncarvalho/.local/lib/python3.8/site-packages/pandas/core/generic.py?line=551'>552</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo axis named \u001b[39m\u001b[39m{\u001b[39;00maxis\u001b[39m}\u001b[39;00m\u001b[39m for object type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: No axis named 6 for object type Series"
     ]
    }
   ],
   "source": [
    "for i in a:\n",
    "    print(df.iloc(i))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
